

GOAL: to use a basic RL agent to complete a minigame, and watch it get better from initial NN output actions
to the end. MAYBE see examples to do so. Tensorflow or KERAS!
    MY idea: state -> policy ->(output)goal-state. says "go to this state".
            Then input both current and target state into a simple-dense NN to get the next action.
            LATER PLANNING ASPECT:Maybe have a simulator that does next-n actions to check? this is the MODEL of the world ?
--------------

NEXT: See how the score changes with movement. Print it out or debug with a random agent that moves around.


Currently, you're moving to the rock as the neutral, try moving to the resource field. What subtype is that ??
Print the score.
What is "score cumulative array" meaning [450   8   3  50 400   0   0   0   0   0   0   0   0]
    Im guessing it is total, unit score, resource score etc. THIS could be information to shift attention.

Initially keep the marine in the center and fixed map, get the RL agent to learn something !!

Add a win condition when resources collected is >500
Add a time limit (google how), and win if resource > 500.


In actions.py
you have an informative code with some lists for action types


NEXT:  -----------  SEE THE ACTIONS IN THE LIST AND XLATE THEM